# -*- coding: utf-8 -*-
"""LVADSUSR154_HareeshKumaar_Fin_Lab4.ipynb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IsefTOoLf6Njme9mPFiIaxZ4lMShyIiT
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
import warnings
import numpy as np
import pandas as pd
import re
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
from sklearn.tree import export_graphviz
from sklearn.impute import KNNImputer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, IsolationForest
from sklearn.model_selection import cross_val_score
from xgboost import XGBClassifier
import xgboost
from lightgbm import LGBMClassifier
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import confusion_matrix, classification_report, f1_score, roc_curve, roc_auc_score, precision_recall_curve, auc, r2_score, mean_squared_error, accuracy_score, recall_score, silhouette_score, silhouette_samples
warnings.filterwarnings('ignore')
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt

df = pd.read_csv("/content/anomaly_train.csv")

df.head()

df.shape

df.isna().sum()

df.duplicated().sum()

le = LabelEncoder()
df.Type = le.fit_transform(df.Type)
df.Location = le.fit_transform(df.Location)

# Create a new dataframe with the selected features
X = df[['Amount','Location','Type','User']]

# Fit an Isolation Forest model to the data
model = IsolationForest(n_estimators=100, contamination=0.1)
model.fit(X)

# Predict the anomalies in the data
y_pred = model.predict(X)

# Add the predicted anomaly scores to the original dataframe
df['anomaly_score'] = model.decision_function(X)
df['anomaly'] = y_pred

anomalies = df.loc[df['anomaly'] == -1]

plt.scatter(df['Amount'],df['anomaly_score'],label='normal')
plt.scatter(anomalies['Amount'],anomalies['anomaly_score'],label='anomaly')
plt.xlabel('Amount')
plt.ylabel('anomaly_score')
plt.legend()
plt.show()

df['is_anomaly'] = df['anomaly'].map({-1:"yes",1:"no"})

df

